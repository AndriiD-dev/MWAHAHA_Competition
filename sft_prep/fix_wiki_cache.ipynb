{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T00:42:47.177797Z",
     "start_time": "2025-12-16T00:42:47.073399Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "WIKI_SUMMARY_URL = \"https://en.wikipedia.org/api/rest_v1/page/summary/{}\"\n",
    "WIKI_SEARCH_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# Put something descriptive here (Wikimedia expects this)\n",
    "WIKI_HEADERS = {\n",
    "    \"User-Agent\": \"MWAHAHA/1.0 (contact: dardemtum@gmail.com) humor-generation\"\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_one_line(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def safe_word(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Conservative sanitizer for Wikipedia titles:\n",
    "    - keeps letters, numbers, spaces, hyphens, apostrophes\n",
    "    - strips everything else\n",
    "    \"\"\"\n",
    "    s = normalize_one_line(s)\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"[^A-Za-z0-9 \\-']\", \"\", s).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def looks_like_disambiguation(extract: str, page_type: str | None) -> bool:\n",
    "    t = (extract or \"\").strip().lower()\n",
    "    if page_type and page_type.strip().lower() == \"disambiguation\":\n",
    "        return True\n",
    "    if \"may refer to:\" in t:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def word_variants_for_wiki(word: str) -> List[str]:\n",
    "    w = safe_word(word)\n",
    "    if not w:\n",
    "        return []\n",
    "\n",
    "    variants = [w]\n",
    "    wl = w.lower()\n",
    "\n",
    "    # all caps noise\n",
    "    if w.isupper() and len(w) >= 4:\n",
    "        variants.append(w.title())\n",
    "        variants.append(w.lower())\n",
    "\n",
    "    # bullies -> bully\n",
    "    if wl.endswith(\"ies\") and len(wl) > 4:\n",
    "        variants.append(w[:-3] + \"y\")\n",
    "\n",
    "    # watches -> watch, boxes -> box\n",
    "    if wl.endswith(\"es\") and len(wl) > 4:\n",
    "        variants.append(w[:-2])\n",
    "\n",
    "    # astronauts -> astronaut\n",
    "    if wl.endswith(\"s\") and len(wl) > 3 and not wl.endswith(\"ss\"):\n",
    "        variants.append(w[:-1])\n",
    "\n",
    "    # deduplicate case-insensitive\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for v in variants:\n",
    "        key = v.lower()\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_summary(title: str) -> Tuple[str, str]:\n",
    "    t = safe_word(title)\n",
    "    if not t:\n",
    "        return (\"\", \"\")\n",
    "\n",
    "    url = WIKI_SUMMARY_URL.format(requests.utils.quote(t))\n",
    "    try:\n",
    "        r = requests.get(url, headers=WIKI_HEADERS, timeout=12)\n",
    "        if r.status_code != 200:\n",
    "            return (\"\", \"\")\n",
    "        data = r.json()\n",
    "        extract = normalize_one_line(data.get(\"extract\", \"\") or \"\")\n",
    "        page_type = normalize_one_line(data.get(\"type\", \"\") or \"\")\n",
    "        return (extract, page_type)\n",
    "    except Exception:\n",
    "        return (\"\", \"\")\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=4096)\n",
    "def search_titles(query: str) -> List[str]:\n",
    "    q = safe_word(query)\n",
    "    if not q:\n",
    "        return []\n",
    "\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": q,\n",
    "        \"format\": \"json\",\n",
    "        \"utf8\": 1,\n",
    "        \"srlimit\": 6,\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(WIKI_SEARCH_URL, params=params, headers=WIKI_HEADERS, timeout=12)\n",
    "        if r.status_code != 200:\n",
    "            return []\n",
    "        data = r.json()\n",
    "        items = (data.get(\"query\", {}) or {}).get(\"search\", []) or []\n",
    "        titles = []\n",
    "        for it in items:\n",
    "            title = normalize_one_line(it.get(\"title\", \"\") or \"\")\n",
    "            if title:\n",
    "                titles.append(title)\n",
    "        return titles\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=8192)\n",
    "def get_wikipedia_extract_cached(word: str) -> str:\n",
    "    w = safe_word(word)\n",
    "    if not w:\n",
    "        return \"\"\n",
    "\n",
    "    # 1) direct try (with variants)\n",
    "    for cand in word_variants_for_wiki(w):\n",
    "        extract, page_type = fetch_summary(cand)\n",
    "        if not extract:\n",
    "            continue\n",
    "        if looks_like_disambiguation(extract, page_type):\n",
    "            continue\n",
    "        return extract\n",
    "\n",
    "    # 2) resolve via search (skip obvious disambiguation titles)\n",
    "    for q in word_variants_for_wiki(w):\n",
    "        for title in search_titles(q):\n",
    "            if title.lower().endswith(\"(disambiguation)\"):\n",
    "                continue\n",
    "            extract, page_type = fetch_summary(title)\n",
    "            if not extract:\n",
    "                continue\n",
    "            if looks_like_disambiguation(extract, page_type):\n",
    "                continue\n",
    "            return extract\n",
    "\n",
    "    return \"\"\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T00:42:47.977101Z",
     "start_time": "2025-12-16T00:42:47.927992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CACHE_IN = Path(\"wiki_extract_cache.json\")\n",
    "CACHE_OUT = Path(\"wiki_extract_cache_updated.json\")\n",
    "\n",
    "extracts = json.loads(CACHE_IN.read_text(encoding=\"utf-8\"))\n",
    "print(\"Loaded cache entries:\", len(extracts))\n",
    "\n",
    "def is_bad_extract(x: str) -> bool:\n",
    "    t = (x or \"\").strip().lower()\n",
    "    return (t == \"\") or (\"may refer to:\" in t)\n",
    "\n",
    "bad_words = [w for w, ex in extracts.items() if is_bad_extract(ex)]\n",
    "print(\"Bad entries to rerun:\", len(bad_words))\n",
    "print(\"Sample bad words:\", bad_words[:30])\n"
   ],
   "id": "5a394d2f721ce67f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache entries: 8892\n",
      "Bad entries to rerun: 2711\n",
      "Sample bad words: ['AAA', 'ACKBAR', 'AHAHAHAHAHAHAHAHAHA', 'AMA', 'ANGRY', 'APR', 'ARRRGHH', 'ARRRRRR', 'ATV', 'AYE', 'AYYEEEE', 'Aaaand', 'Abe', 'Abu', 'Accord', 'Act', 'Adbl', 'Addictionary', 'Advi', 'Age', 'Ages', 'Ajit', 'Alan', 'Albanian', 'Albert', 'Alcohol', 'Alentine', 'Alexa', 'Alfred', 'Algaebra']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T02:11:42.092904Z",
     "start_time": "2025-12-16T00:45:31.142303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Inputs/outputs\n",
    "CACHE_IN = Path(\"wiki_extract_cache.json\")\n",
    "RERUN_RESULTS_JSON = Path(\"wiki_rerun_results.json\")\n",
    "RERUN_LOG_TSV = Path(\"wiki_rerun_log.tsv\")\n",
    "CACHE_OUT = Path(\"wiki_extract_cache_updated.json\")\n",
    "\n",
    "SLEEP_SECONDS = 0.20\n",
    "PRINT_EVERY = 50\n",
    "\n",
    "extracts = json.loads(CACHE_IN.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def is_bad_extract(x: str) -> bool:\n",
    "    t = (x or \"\").strip().lower()\n",
    "    return (t == \"\") or (\"may refer to:\" in t)\n",
    "\n",
    "bad_words = [w for w, ex in extracts.items() if is_bad_extract(ex)]\n",
    "print(\"Loaded cache entries:\", len(extracts))\n",
    "print(\"Bad entries to rerun:\", len(bad_words))\n",
    "\n",
    "\n",
    "def word_variants(word: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates a small set of normalized variants to try.\n",
    "    We will use these variants as:\n",
    "    - direct summary title queries\n",
    "    - search queries (resolver)\n",
    "    \"\"\"\n",
    "    w = safe_word(word)\n",
    "    if not w:\n",
    "        return []\n",
    "\n",
    "    vars_ = [w]\n",
    "\n",
    "    # lower/title variants (helps for ALL CAPS or weird casing)\n",
    "    vars_.append(w.lower())\n",
    "    vars_.append(w.title())\n",
    "\n",
    "    wl = w.lower()\n",
    "\n",
    "    # plural / inflection heuristics\n",
    "    if wl.endswith(\"ies\") and len(wl) > 4:\n",
    "        vars_.append(w[:-3] + \"y\")\n",
    "\n",
    "    if wl.endswith(\"es\") and len(wl) > 4:\n",
    "        vars_.append(w[:-2])\n",
    "\n",
    "    if wl.endswith(\"s\") and len(wl) > 3 and not wl.endswith(\"ss\"):\n",
    "        vars_.append(w[:-1])\n",
    "\n",
    "    # de-duplicate case-insensitive\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for v in vars_:\n",
    "        v2 = safe_word(v)\n",
    "        if not v2:\n",
    "            continue\n",
    "        key = v2.lower()\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(v2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_extract_with_trace(word: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns a trace dict:\n",
    "      {\n",
    "        \"input_word\": ...,\n",
    "        \"normalized_variants\": [...],\n",
    "        \"best_extract\": \"...\",\n",
    "        \"best_title\": \"...\",\n",
    "        \"method\": \"direct|search|none\",\n",
    "        \"status\": \"ok|empty|disambiguation\",\n",
    "      }\n",
    "    \"\"\"\n",
    "    variants = word_variants(word)\n",
    "    trace = {\n",
    "        \"input_word\": word,\n",
    "        \"normalized_variants\": variants,\n",
    "        \"best_extract\": \"\",\n",
    "        \"best_title\": \"\",\n",
    "        \"method\": \"none\",\n",
    "        \"status\": \"empty\",\n",
    "    }\n",
    "    if not variants:\n",
    "        return trace\n",
    "\n",
    "    # 1) Direct attempts with variants\n",
    "    for cand in variants:\n",
    "        ex, page_type = fetch_summary(cand)\n",
    "        ex = normalize_one_line(ex)\n",
    "        if not ex:\n",
    "            continue\n",
    "        if looks_like_disambiguation(ex, page_type):\n",
    "            trace[\"status\"] = \"disambiguation\"\n",
    "            continue\n",
    "\n",
    "        trace[\"best_extract\"] = ex\n",
    "        trace[\"best_title\"] = cand\n",
    "        trace[\"method\"] = \"direct\"\n",
    "        trace[\"status\"] = \"ok\"\n",
    "        return trace\n",
    "\n",
    "    # 2) Search resolver attempts\n",
    "    # Use each variant as a query; pick first non-disambiguation title with a real extract\n",
    "    for q in variants:\n",
    "        titles = search_titles(q)\n",
    "        for title in titles:\n",
    "            if title.lower().endswith(\"(disambiguation)\"):\n",
    "                continue\n",
    "            ex, page_type = fetch_summary(title)\n",
    "            ex = normalize_one_line(ex)\n",
    "            if not ex:\n",
    "                continue\n",
    "            if looks_like_disambiguation(ex, page_type):\n",
    "                trace[\"status\"] = \"disambiguation\"\n",
    "                continue\n",
    "\n",
    "            trace[\"best_extract\"] = ex\n",
    "            trace[\"best_title\"] = title\n",
    "            trace[\"method\"] = \"search\"\n",
    "            trace[\"status\"] = \"ok\"\n",
    "            return trace\n",
    "\n",
    "    # nothing found\n",
    "    return trace\n",
    "\n",
    "\n",
    "# Rerun and store separate results\n",
    "rerun_results = {}\n",
    "log_rows = []\n",
    "updated = 0\n",
    "still_bad = 0\n",
    "\n",
    "t0 = time.time()\n",
    "for i, w in enumerate(bad_words, start=1):\n",
    "    old_ex = normalize_one_line(extracts.get(w, \"\"))\n",
    "\n",
    "    trace = get_extract_with_trace(w)\n",
    "    new_ex = trace[\"best_extract\"]\n",
    "\n",
    "    # Save rerun result separately regardless of whether we update the main cache\n",
    "    rerun_results[w] = trace\n",
    "\n",
    "    # Decide if we should update main cache:\n",
    "    # update only if new extract is:\n",
    "    # - non-empty\n",
    "    # - not disambiguation\n",
    "    # - longer than old extract\n",
    "    should_update = bool(new_ex) and (\"may refer to:\" not in new_ex.lower()) and (len(new_ex) > len(old_ex))\n",
    "\n",
    "    if should_update:\n",
    "        extracts[w] = new_ex\n",
    "        updated += 1\n",
    "        action = \"UPDATED\"\n",
    "    else:\n",
    "        still_bad += 1\n",
    "        action = \"SKIPPED\"\n",
    "\n",
    "    log_rows.append({\n",
    "        \"word\": w,\n",
    "        \"action\": action,\n",
    "        \"old_len\": len(old_ex),\n",
    "        \"new_len\": len(new_ex),\n",
    "        \"method\": trace[\"method\"],\n",
    "        \"best_title\": trace[\"best_title\"],\n",
    "        \"status\": trace[\"status\"],\n",
    "        \"old_extract_preview\": old_ex[:120],\n",
    "        \"new_extract_preview\": new_ex[:120],\n",
    "    })\n",
    "\n",
    "    if i % PRINT_EVERY == 0:\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"{i}/{len(bad_words)} rerun (elapsed {elapsed:.1f}s). updated={updated}, skipped={still_bad}. example={w!r}\")\n",
    "        if trace[\"best_title\"]:\n",
    "            print(\"  best_title:\", trace[\"best_title\"])\n",
    "        if new_ex:\n",
    "            print(\"  new:\", new_ex[:200])\n",
    "\n",
    "    time.sleep(SLEEP_SECONDS)\n",
    "\n",
    "# Save rerun-only results (for later inspection)\n",
    "RERUN_RESULTS_JSON.write_text(json.dumps(rerun_results, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved rerun results:\", RERUN_RESULTS_JSON.resolve())\n",
    "\n",
    "# Save human-readable log\n",
    "import pandas as pd\n",
    "pd.DataFrame(log_rows).to_csv(RERUN_LOG_TSV, sep=\"\\t\", index=False)\n",
    "print(\"Saved rerun log:\", RERUN_LOG_TSV.resolve())\n",
    "\n",
    "# Save updated cache as a new file (does not overwrite original)\n",
    "CACHE_OUT.write_text(json.dumps(extracts, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"\\nDone.\")\n",
    "print(\"Updated entries:\", updated)\n",
    "print(\"Skipped (still bad or not improved):\", still_bad)\n",
    "print(\"Saved updated cache:\", CACHE_OUT.resolve())\n"
   ],
   "id": "756fe74ca1f89747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache entries: 8892\n",
      "Bad entries to rerun: 2711\n",
      "50/2711 rerun (elapsed 37.5s). updated=40, skipped=10. example='Areptile'\n",
      "100/2711 rerun (elapsed 144.4s). updated=85, skipped=15. example='Belle'\n",
      "  best_title: Belle Delphine\n",
      "  new: Mary-Belle Kirschner, better known as Belle Delphine, is a South African-born British social media personality, pornographic actress, model, and YouTuber. Her social media accounts feature erotic and \n",
      "150/2711 rerun (elapsed 244.0s). updated=131, skipped=19. example='CASHEWWWW'\n",
      "200/2711 rerun (elapsed 325.1s). updated=169, skipped=31. example='Clop'\n",
      "  best_title: CLOP\n",
      "  new: CLOP is a 2012 Flash game made by Australian game designer Bennett Foddy. It is considered a spiritual successor to Foddy's previous game, QWOP, released four years prior which had gone on to become a\n",
      "250/2711 rerun (elapsed 422.7s). updated=213, skipped=37. example='Dalai'\n",
      "  best_title: 14th Dalai Lama\n",
      "  new: The 14th Dalai Lama is the incumbent Dalai Lama, the highest spiritual leader and head of Tibetan Buddhism. He served as the resident spiritual and temporal leader of Tibet before 1959 and subsequentl\n",
      "300/2711 rerun (elapsed 532.3s). updated=256, skipped=44. example='Double'\n",
      "  best_title: Double-double\n",
      "  new: In basketball, a double-double is a single-game performance in which a player accumulates ten or more in two of the following five statistical categories: points, rebounds, assists, steals, and blocke\n",
      "350/2711 rerun (elapsed 621.4s). updated=290, skipped=60. example='EweTube'\n",
      "  best_title: Loch Ewe distillery\n",
      "  new: Loch Ewe distillery in Drumchork near Aultbea in the Scottish Highlands was the smallest legally operated distillery in Scotland. It was set up in 2005 by the owner of the Drumchork Lodge Hotel in a d\n",
      "400/2711 rerun (elapsed 706.3s). updated=332, skipped=68. example='Froglights'\n",
      "  best_title: Sarah Abbott\n",
      "  new: Sarah Abbott is a Canadian filmmaker and artist. Abbott graduated from Queen's University with a major in Film Studies and Drama, she received a Master of Fine Arts degree for Art Video at Syracuse Un\n",
      "450/2711 rerun (elapsed 793.7s). updated=366, skipped=84. example='Haaaaaaay'\n",
      "500/2711 rerun (elapsed 881.2s). updated=406, skipped=94. example='Hoover'\n",
      "  best_title: Herbert Hoover\n",
      "  new: Herbert Clark Hoover was the 31st president of the United States, serving from 1929 to 1933. A wealthy mining engineer before his presidency, Hoover led the wartime Commission for Relief in Belgium an\n",
      "550/2711 rerun (elapsed 1035.2s). updated=448, skipped=102. example='Jenny'\n",
      "  best_title: Jenny McCarthy\n",
      "  new: Jennifer Ann McCarthy-Wahlberg is an American actress, model, television personality, and anti-vaccine activist. She began her career in 1993 as a nude model for Playboy magazine and was later named t\n",
      "600/2711 rerun (elapsed 1129.6s). updated=490, skipped=110. example='Krypt'\n",
      "  best_title: Krypts\n",
      "  new: Krypts is a Finnish death metal band from Helsinki, Uusimaa. Their first studio album, Unending Degradation, was released through Dark Descent Records on 19 February 2013.\n",
      "650/2711 rerun (elapsed 1254.3s). updated=533, skipped=117. example='Mac'\n",
      "  best_title: Fleetwood Mac\n",
      "  new: Fleetwood Mac were a British-American rock band formed in London in 1967 by singer and guitarist Peter Green. Green named the band by combining the surnames of drummer Mick Fleetwood and bassist John \n",
      "700/2711 rerun (elapsed 1371.5s). updated=576, skipped=124. example='Minton'\n",
      "  best_title: Mintons\n",
      "  new: Mintons was a major company in Staffordshire pottery, \"Europe's leading ceramic factory during the Victorian era\", an independent business from 1793 to 1968. It was a leader in ceramic design, working\n",
      "750/2711 rerun (elapsed 1473.9s). updated=613, skipped=137. example='Oinkment'\n",
      "  best_title: List of animal sounds\n",
      "  new: Certain words in the English language represent animal sounds: the noises and vocalizations of particular animals, especially noises used by animals for communication. The words can be used as verbs o\n",
      "800/2711 rerun (elapsed 1565.0s). updated=657, skipped=143. example='Piiig'\n",
      "850/2711 rerun (elapsed 1651.6s). updated=697, skipped=153. example='Race'\n",
      "  best_title: Ferrari\n",
      "  new: Ferrari S.p.A. is an Italian luxury sports car manufacturer based in Maranello. Founded in 1939 by Enzo Ferrari (1898–1988), the company built its first car in 1940, adopted its current name in 1945, \n",
      "900/2711 rerun (elapsed 1739.4s). updated=743, skipped=157. example='Salin'\n",
      "  best_title: Sasu Salin\n",
      "  new: Sasu Antreas Salin is a Finnish professional basketball player who plays for Spanish team Estudiantes. Standing at 1.91 m he plays at the shooting guard position. Salin also captains the Finland natio\n",
      "950/2711 rerun (elapsed 1832.9s). updated=790, skipped=160. example='Solo'\n",
      "  best_title: Solo Leveling\n",
      "  new: Solo Leveling, also alternatively translated as Only I Level Up is a South Korean fantasy web novel written by Chugong. It was serialized in Kakao's digital comic and fiction platform KakaoPage beginn\n",
      "1000/2711 rerun (elapsed 1930.9s). updated=833, skipped=167. example='Teddy'\n",
      "  best_title: Teddy bear\n",
      "  new: A teddy bear, or simply a teddy, is a stuffed toy in the form of a bear. The teddy bear was named by Morris Michtom after the 26th president of the United States, Theodore Roosevelt; it was developed \n",
      "1050/2711 rerun (elapsed 2021.6s). updated=874, skipped=176. example='UNO'\n",
      "  best_title: Uno (card game)\n",
      "  new: Uno, stylized as UNO, is a proprietary American shedding-type card game originally developed in 1971 by Merle Robbins in Reading, Ohio, a suburb of Cincinnati, that housed International Games Inc., a \n",
      "1100/2711 rerun (elapsed 2115.3s). updated=916, skipped=184. example='Welsh'\n",
      "  best_title: Welsh language\n",
      "  new: Welsh is a Celtic language of the Brittonic subgroup that is native to the Welsh people. Welsh is spoken natively in Wales by about 18% of the population, by some in England, and in Y Wladfa.\n",
      "1150/2711 rerun (elapsed 2216.3s). updated=955, skipped=195. example='accessories'\n",
      "  best_title: Fashion accessory\n",
      "  new: In fashion, an accessory is an item used to contribute, in a secondary manner, to an individual's outfit. Accessories are often chosen to complete an outfit and complement the wearer's look. They have\n",
      "1200/2711 rerun (elapsed 2300.7s). updated=997, skipped=203. example='ark'\n",
      "  best_title: Noah's Ark\n",
      "  new: Noah's Ark is the boat in the Genesis flood narrative through which God spares Noah, his family, and one pair of every animal species in the world from a global deluge.\n",
      "1250/2711 rerun (elapsed 2394.5s). updated=1041, skipped=209. example='beers'\n",
      "  best_title: beer\n",
      "  new: Beer is an alcoholic beverage produced by the brewing and fermentation of starches from cereal grain—most commonly malted barley, although wheat, maize, rice, and oats are also used. The grain is mash\n",
      "1300/2711 rerun (elapsed 2482.2s). updated=1087, skipped=213. example='break'\n",
      "  best_title: Break, Break, Break\n",
      "  new: \"Break, Break, Break\" is a poem by Alfred, Lord Tennyson written during early 1835 and published in 1842. The poem is an elegy that describes Tennyson's feelings of loss after Arthur Henry Hallam died\n",
      "1350/2711 rerun (elapsed 2593.2s). updated=1131, skipped=219. example='cases'\n",
      "  best_title: Grammatical case\n",
      "  new: A grammatical case is a category of nouns and noun modifiers that corresponds to one or more potential grammatical functions for a nominal group in a wording. In various languages, nominal groups cons\n",
      "1400/2711 rerun (elapsed 2693.3s). updated=1176, skipped=224. example='clean'\n",
      "  best_title: Clean, Clean\n",
      "  new: \"Clean, Clean\" is a song composed by Trevor Horn, Geoff Downes and Bruce Woolley, with additional composition by Thomas Dolby. It was recorded first by the latter for Woolley's band Bruce Woolley and \n",
      "1450/2711 rerun (elapsed 2799.0s). updated=1218, skipped=232. example='contrarian'\n",
      "  best_title: Contrarian investing\n",
      "  new: Contrarian investing is an investment strategy that is characterized by purchasing and selling in contrast to the prevailing sentiment of the time.\n",
      "1500/2711 rerun (elapsed 2897.4s). updated=1260, skipped=240. example='dates'\n",
      "  best_title: List of dates predicted for apocalyptic events\n",
      "  new: Predictions of apocalyptic events that will result in the extinction of humanity, a collapse of civilization, or the destruction of the planet have been made since at least the beginning of the Common\n",
      "1550/2711 rerun (elapsed 2980.8s). updated=1303, skipped=247. example='direction'\n",
      "  best_title: One Direction\n",
      "  new: One Direction, often shortened to 1D, were an English–Irish pop boy band formed in London in 2010. The group consisted of Niall Horan, Liam Payne, Harry Styles, Louis Tomlinson and Zayn Malik. The gro\n",
      "1600/2711 rerun (elapsed 3080.7s). updated=1347, skipped=253. example='effect'\n",
      "  best_title: Mass Effect\n",
      "  new: Mass Effect is a military science fiction media franchise created by Casey Hudson. The franchise depicts a distant future where humanity and several alien civilizations have colonized the galaxy using\n",
      "1650/2711 rerun (elapsed 3172.4s). updated=1389, skipped=261. example='figure'\n",
      "  best_title: Figure skating\n",
      "  new: Figure skating is a sport in which individuals, pairs, or groups perform on figure skates on ice. It was the first winter sport to be included in the Olympic Games, with its introduction occurring at \n",
      "1700/2711 rerun (elapsed 3280.1s). updated=1433, skipped=267. example='gon'\n",
      "  best_title: Gon Freecss\n",
      "  new: Gon Freecss is the protagonist of Yoshihiro Togashi's manga series Hunter × Hunter. Gon is a young boy who discovers his father, Ging, who left Gon at a young age, is actually a world-renowned Hunter,\n",
      "1750/2711 rerun (elapsed 3363.2s). updated=1476, skipped=274. example='heroes'\n",
      "  best_title: hero\n",
      "  new: A hero is a real person or fictional character who, in the face of danger, combats adversity through feats of ingenuity, courage, or strength. The original hero type of classical epics did such things\n",
      "1800/2711 rerun (elapsed 3459.0s). updated=1513, skipped=287. example='impression'\n",
      "  best_title: Impression, Sunrise\n",
      "  new: Impression, Sunrise is an 1872 painting by Claude Monet first shown at what would become known as the \"Exhibition of the Impressionists\" in Paris in April, 1874. The painting is credited with inspirin\n",
      "1850/2711 rerun (elapsed 3563.4s). updated=1557, skipped=293. example='kkake'\n",
      "1900/2711 rerun (elapsed 3667.8s). updated=1597, skipped=303. example='loads'\n",
      "  best_title: Structural load\n",
      "  new: A structural load or structural action is a mechanical load applied to structural elements. A load causes stress, deformation, displacement or acceleration in a structure. Structural analysis, a disci\n",
      "1950/2711 rerun (elapsed 3753.4s). updated=1632, skipped=318. example='millionheir'\n",
      "  best_title: Mystery Case Files\n",
      "  new: Mystery Case Files is a video game series originally developed by the internal studios of Big Fish Games. Sequels were then developed by Elephant Games between 2013 and 2014 and Eipix Entertainment be\n",
      "2000/2711 rerun (elapsed 3847.1s). updated=1678, skipped=322. example='nines'\n",
      "  best_title: nine\n",
      "  new: 9 (nine) is the natural number following 8 and preceding 10.\n",
      "2050/2711 rerun (elapsed 3945.4s). updated=1719, skipped=331. example='packet'\n",
      "  best_title: Packet switching\n",
      "  new: In telecommunications, packet switching is a method of grouping data into short messages in fixed format, i.e., packets, that are transmitted over a telecommunications network. Packets consist of a he\n",
      "2100/2711 rerun (elapsed 4030.0s). updated=1764, skipped=336. example='pickles'\n",
      "  best_title: pickl\n",
      "  new: Pickl is a chain of American-style fast food burger joints founded in the UAE in 2019. As of September 2023, Pickl has 18 locations in the UAE plus 2 franchised international restaurants in Bahrain, t\n",
      "2150/2711 rerun (elapsed 4114.5s). updated=1808, skipped=342. example='practice'\n",
      "  best_title: The Practice\n",
      "  new: The Practice is an American legal drama television series created by David E. Kelley centering on partners and associates at a Boston law firm. The show ran for eight seasons on ABC, from March 4, 199\n",
      "2200/2711 rerun (elapsed 4207.1s). updated=1850, skipped=350. example='raider'\n",
      "  best_title: Tomb Raider\n",
      "  new: Tomb Raider, known as Lara Croft: Tomb Raider from 2001 to 2008, is a media franchise that originated with an action-adventure video game series created by British video game developer Core Design. Th\n",
      "2250/2711 rerun (elapsed 4305.4s). updated=1892, skipped=358. example='reunion'\n",
      "  best_title: Réunion\n",
      "  new: Runion is a surname. Notable people with the surname include:Chris Runion, American politician Garrett Runion, American collegiate golf coach\n",
      "2300/2711 rerun (elapsed 4397.1s). updated=1935, skipped=365. example='scales'\n",
      "  best_title: Prunella Scales\n",
      "  new: Prunella Margaret Rumney West, known professionally as Prunella Scales, was an English actress. She is best known for her portrayal of Sybil Fawlty in the BBC television sitcom Fawlty Towers (1975–197\n",
      "2350/2711 rerun (elapsed 4501.9s). updated=1976, skipped=374. example='shin'\n",
      "  best_title: Shin Min-a\n",
      "  new: Yang Min-a, better known by the stage name Shin Min-a (신민아), is a South Korean actress and model best known for starring in television dramas A Love to Kill (2005), My Girlfriend Is a Gumiho (2010), A\n",
      "2400/2711 rerun (elapsed 4600.7s). updated=2021, skipped=379. example='someones'\n",
      "  best_title: To Be Someone\n",
      "  new: To Be Someone is a British film loosely related to the 1979 film, Quadrophenia. The film is directed by Ray Burdis and written by Pete Meadows.\n",
      "2450/2711 rerun (elapsed 4691.5s). updated=2068, skipped=382. example='stops'\n",
      "  best_title: The Machine Stops\n",
      "  new: \"The Machine Stops\" is a science fiction short story by E. M. Forster. After initial publication in The Oxford and Cambridge Review, the story was republished in Forster's The Eternal Moment and Other\n",
      "2500/2711 rerun (elapsed 4782.3s). updated=2112, skipped=388. example='tags'\n",
      "  best_title: Radio-frequency identification\n",
      "  new: Radio-frequency identification (RFID) uses electromagnetic fields to automatically identify and track tags attached to objects. An RFID system consists of a tiny radio transponder called a tag, a radi\n",
      "2550/2711 rerun (elapsed 4892.2s). updated=2156, skipped=394. example='ticket'\n",
      "  best_title: Shadow Ticket\n",
      "  new: Shadow Ticket is a novel by the American author Thomas Pynchon. It was announced by Penguin Press in April 2025 and released that October. The novel, which is set in 1932, centers on a Milwaukee priva\n",
      "2600/2711 rerun (elapsed 4981.1s). updated=2198, skipped=402. example='trouble'\n",
      "  best_title: The Troubles\n",
      "  new: The Troubles were an ethno-nationalist conflict in Northern Ireland that lasted for about 30 years from the late 1960s to 1998. Also known internationally as the Northern Ireland conflict, it began in\n",
      "2650/2711 rerun (elapsed 5070.2s). updated=2238, skipped=412. example='walkie'\n",
      "  best_title: 20 Fenchurch Street\n",
      "  new: 20 Fenchurch Street is a commercial skyscraper in London that takes its name from its address on Fenchurch Street, in the historic City of London financial district. It has been nicknamed \"The Walkie-\n",
      "2700/2711 rerun (elapsed 5150.5s). updated=2281, skipped=419. example='wreck'\n",
      "  best_title: Wreck-It Ralph\n",
      "  new: Wreck-It Ralph is a 2012 American animated comedy film produced by Walt Disney Animation Studios. It was directed by Rich Moore and produced by Clark Spencer, from a screenplay by Phil Johnston and Je\n",
      "Saved rerun results: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_rerun_results.json\n",
      "Saved rerun log: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_rerun_log.tsv\n",
      "\n",
      "Done.\n",
      "Updated entries: 2289\n",
      "Skipped (still bad or not improved): 422\n",
      "Saved updated cache: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_extract_cache_updated.json\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:53:10.358908Z",
     "start_time": "2025-12-16T09:53:09.989386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Use your actual filenames\n",
    "ORIG_CACHE = Path(\"wiki_extract_cache.json\")\n",
    "UPDATED_CACHE = Path(\"wiki_extract_cache_updated.json\")\n",
    "\n",
    "CLEAN_UPDATED_OUT = Path(\"wiki_extract_cache_updated_cleaned.json\")\n",
    "MERGED_OUT = Path(\"wiki_extract_cache_merged.json\")\n",
    "\n",
    "def normalize_one_line(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def is_disambiguation(s: str) -> bool:\n",
    "    t = normalize_one_line(s).lower()\n",
    "    if not t:\n",
    "        return False\n",
    "    return (\"may refer to\" in t) or (\"commonly refers to\" in t)\n",
    "\n",
    "# Load\n",
    "orig = json.loads(ORIG_CACHE.read_text(encoding=\"utf-8\"))\n",
    "upd = json.loads(UPDATED_CACHE.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Loaded original:\", len(orig), \"entries from\", ORIG_CACHE.resolve())\n",
    "print(\"Loaded updated :\", len(upd),  \"entries from\", UPDATED_CACHE.resolve())\n",
    "\n",
    "# 1) Clean updated: blank out disambiguation extracts\n",
    "cleaned_upd = {}\n",
    "blanked = 0\n",
    "for k, v in upd.items():\n",
    "    v_norm = normalize_one_line(v)\n",
    "    if is_disambiguation(v_norm):\n",
    "        cleaned_upd[k] = \"\"\n",
    "        blanked += 1\n",
    "    else:\n",
    "        cleaned_upd[k] = v_norm\n",
    "\n",
    "CLEAN_UPDATED_OUT.write_text(json.dumps(cleaned_upd, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"\\nSaved cleaned updated cache:\", CLEAN_UPDATED_OUT.resolve())\n",
    "print(\"Blanked disambiguation entries:\", blanked)\n",
    "\n",
    "# 2) Merge into original: replace only when updated value is non-empty\n",
    "merged = dict(orig)\n",
    "replaced = 0\n",
    "\n",
    "for k, v_new in cleaned_upd.items():\n",
    "    if not v_new:\n",
    "        continue\n",
    "    if k in merged and normalize_one_line(merged[k]) != v_new:\n",
    "        merged[k] = v_new\n",
    "        replaced += 1\n",
    "\n",
    "MERGED_OUT.write_text(json.dumps(merged, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"\\nSaved merged cache:\", MERGED_OUT.resolve())\n",
    "print(\"Replaced entries:\", replaced)\n"
   ],
   "id": "d56e5b1d79899245",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded original: 8892 entries from /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_extract_cache.json\n",
      "Loaded updated : 8892 entries from /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_extract_cache_updated.json\n",
      "\n",
      "Saved cleaned updated cache: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_extract_cache_updated_cleaned.json\n",
      "Blanked disambiguation entries: 394\n",
      "\n",
      "Saved merged cache: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/sft_prep/wiki_extract_cache_merged.json\n",
      "Replaced entries: 2284\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "351069185f461309"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

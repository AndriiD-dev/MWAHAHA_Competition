{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T00:46:13.661332Z",
     "start_time": "2025-12-28T00:46:13.654967Z"
    }
   },
   "source": [
    "# =========================\n",
    "# Cell 0: Imports + paths\n",
    "# =========================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def find_upwards(start: Path, target: str, max_levels: int = 8) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(max_levels):\n",
    "        candidate = cur / target\n",
    "        if candidate.exists() and candidate.is_dir():\n",
    "            return candidate\n",
    "        cur = cur.parent\n",
    "    raise FileNotFoundError(f\"Could not find '{target}' by walking upwards from {start}\")\n",
    "\n",
    "CWD = Path.cwd()\n",
    "DATASETS_SFT = find_upwards(CWD, \"datasets_sft\")\n",
    "\n",
    "print(\"CWD:\", CWD)\n",
    "print(\"DATASETS_SFT:\", DATASETS_SFT)\n"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:46:13.688089Z",
     "start_time": "2025-12-28T00:46:13.683522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Cell 1: Collect candidate files\n",
    "# ==========================================\n",
    "# We will evaluate thresholds on the *.filtered.csv files (they already contain humor_prob).\n",
    "# If a file does NOT have humor_prob, we will compute it (optional later cells).\n",
    "\n",
    "CATEGORIES = [\"general\", \"pun\", \"satire\"]\n",
    "\n",
    "def list_filtered_csvs() -> List[Path]:\n",
    "    out: List[Path] = []\n",
    "    for cat in CATEGORIES:\n",
    "        d = DATASETS_SFT / cat\n",
    "        if not d.exists():\n",
    "            continue\n",
    "        out.extend(sorted(d.glob(\"*.filtered.csv\")))\n",
    "    return out\n",
    "\n",
    "FILES = list_filtered_csvs()\n",
    "print(\"Found filtered files:\")\n",
    "for p in FILES:\n",
    "    print(\"-\", p.relative_to(DATASETS_SFT))\n"
   ],
   "id": "fb4d0be7d611988e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:46:13.707519Z",
     "start_time": "2025-12-28T00:46:13.702229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Cell 2: Threshold grid you want to test\n",
    "# ==========================================\n",
    "\n",
    "# Change as you like\n",
    "THRESHOLDS = [round(x, 2) for x in\n",
    "              [0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]]\n",
    "\n",
    "THRESHOLDS\n"
   ],
   "id": "8e1e3a83e87e8edb",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:46:14.414002Z",
     "start_time": "2025-12-28T00:46:13.709189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Cell 3: Compute \"kept counts\" per threshold for each file\n",
    "# ==========================================================\n",
    "\n",
    "def counts_for_thresholds(df: pd.DataFrame, thresholds: List[float]) -> Dict[float, int]:\n",
    "    if \"humor_prob\" not in df.columns:\n",
    "        raise ValueError(\"This file does not contain 'humor_prob'. Run the optional scoring notebook first.\")\n",
    "\n",
    "    probs = pd.to_numeric(df[\"humor_prob\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    out: Dict[float, int] = {}\n",
    "    for t in thresholds:\n",
    "        out[t] = int((probs >= t).sum())\n",
    "    return out\n",
    "\n",
    "rows = []\n",
    "for f in FILES:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "    # Some filtered files might already be thresholded (still fine), we just use their humor_prob distribution.\n",
    "    counts = counts_for_thresholds(df, THRESHOLDS)\n",
    "\n",
    "    row = {\n",
    "        \"category\": f.parent.name,\n",
    "        \"file\": f.name,\n",
    "        \"rows_in_file\": int(len(df)),\n",
    "        **{f\"t>={t:.2f}\": counts[t] for t in THRESHOLDS},\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values([\"category\", \"file\"]).reset_index(drop=True)\n",
    "display(summary)\n"
   ],
   "id": "7761c41aff127c2e",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:46:14.420291Z",
     "start_time": "2025-12-28T00:46:14.415265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Cell 4: Save report to JSON + CSV (so it is easy to compare)\n",
    "# ==========================================================\n",
    "\n",
    "out_csv = DATASETS_SFT / \"threshold_sweep_report.csv\"\n",
    "out_json = DATASETS_SFT / \"threshold_sweep_report.json\"\n",
    "\n",
    "summary.to_csv(out_csv, index=False)\n",
    "out_json.write_text(summary.to_json(orient=\"records\", indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Wrote:\", out_csv)\n",
    "print(\"Wrote:\", out_json)\n"
   ],
   "id": "94baf59bd1f84c2b",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:52:14.292218Z",
     "start_time": "2025-12-28T00:52:14.275548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Cell 5: Optional - pretty per-file view\n",
    "# ==========================================================\n",
    "\n",
    "def show_file_curve(file_name_contains: str):\n",
    "    match = summary[summary[\"file\"].str.contains(file_name_contains, case=False, regex=False)]\n",
    "    if match.empty:\n",
    "        print(\"No match.\")\n",
    "        return\n",
    "    display(match)\n",
    "\n",
    "# Example:\n",
    "show_file_curve(\"general_merged.filtered\")\n"
   ],
   "id": "1493ef11f7c2ebe0",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:52:19.228242Z",
     "start_time": "2025-12-28T00:52:18.201918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# Cell: counts per base dataset in GENERAL at threshold 0.95\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "THRESHOLD = 0.95\n",
    "\n",
    "general_file = DATASETS_SFT / \"general\" / \"general_merged.filtered.csv\"\n",
    "if not general_file.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {general_file}\")\n",
    "\n",
    "df = pd.read_csv(general_file)\n",
    "\n",
    "# Safety: ensure required columns exist\n",
    "required = {\"id\", \"humor_prob\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in {general_file.name}: {missing}\")\n",
    "\n",
    "# Apply threshold\n",
    "df[\"humor_prob\"] = pd.to_numeric(df[\"humor_prob\"], errors=\"coerce\").fillna(0.0)\n",
    "kept = df[df[\"humor_prob\"] >= THRESHOLD].copy()\n",
    "\n",
    "# Extract base dataset name from id: \"<dataset>::<split>::<row_id>\"\n",
    "# If parsing fails, put \"UNKNOWN\"\n",
    "def extract_base_dataset(x: str) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        return \"UNKNOWN\"\n",
    "    parts = x.split(\"::\", 2)\n",
    "    return parts[0] if len(parts) >= 1 and parts[0] else \"UNKNOWN\"\n",
    "\n",
    "kept[\"base_dataset\"] = kept[\"id\"].map(extract_base_dataset)\n",
    "\n",
    "counts = (\n",
    "    kept.groupby(\"base_dataset\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"count_at_0.95\")\n",
    ")\n",
    "\n",
    "print(\"GENERAL file:\", general_file)\n",
    "print(\"Total rows in general:\", len(df))\n",
    "print(f\"Rows kept at threshold {THRESHOLD}:\", len(kept))\n",
    "\n",
    "display(counts)\n"
   ],
   "id": "63fa9ed22aaa0544",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:59:31.417811Z",
     "start_time": "2025-12-28T00:59:31.410936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_short_jokes_texts_from_general(\n",
    "    datasets_sft_root,\n",
    "    threshold: float = 0.95,\n",
    "    general_filename: str = \"general_merged.filtered.csv\",\n",
    "    max_print: int | None = 200,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract all rows from the GENERAL merged file that come from base dataset 'short_jokes'\n",
    "    (parsed from id: \"<dataset>::<split>::<row_id>\") and have humor_prob >= threshold.\n",
    "\n",
    "    Returns a list of raw_text strings and also prints them (optionally capped).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "\n",
    "    datasets_sft_root = Path(datasets_sft_root)\n",
    "    general_path = datasets_sft_root / \"general\" / general_filename\n",
    "    if not general_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {general_path}\")\n",
    "\n",
    "    df = pd.read_csv(general_path)\n",
    "\n",
    "    required = {\"id\", \"raw_text\", \"humor_prob\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in {general_path.name}: {missing}\")\n",
    "\n",
    "    # Parse + filter\n",
    "    df[\"humor_prob\"] = pd.to_numeric(df[\"humor_prob\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    base_ds = df[\"id\"].astype(str).str.split(\"::\", n=2, expand=True)[0]\n",
    "    mask = (base_ds == \"one_liners\") & (df[\"humor_prob\"] >= float(threshold))\n",
    "\n",
    "    texts = df.loc[mask, \"raw_text\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    print(\"GENERAL:\", general_path)\n",
    "    print(\"Base dataset:\", \"one_liners\")\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print(\"Count:\", len(texts))\n",
    "    print()\n",
    "\n",
    "    if max_print is None:\n",
    "        to_show = texts\n",
    "    else:\n",
    "        to_show = texts[:max_print]\n",
    "\n",
    "    for i, t in enumerate(to_show, start=1):\n",
    "        print(f\"{i}. {t}\")\n",
    "\n",
    "    if max_print is not None and len(texts) > max_print:\n",
    "        print(f\"\\n... printed {max_print} of {len(texts)} texts\")\n",
    "\n",
    "    return texts\n"
   ],
   "id": "a6a91066080ea387",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:59:33.099833Z",
     "start_time": "2025-12-28T00:59:32.135146Z"
    }
   },
   "cell_type": "code",
   "source": "texts = list_short_jokes_texts_from_general(DATASETS_SFT, threshold=0.95, max_print=100)\n",
   "id": "fd94ffb04e4c8031",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "6477945c8f62e06a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99358c6e",
   "metadata": {},
   "source": [
    "# Create 100-row test subsets (always CSV outputs)\n",
    "\n",
    "Reads:\n",
    "- `data/task-a-title.csv` (may be one-headline-per-line, sometimes not valid comma-separated values)\n",
    "- `data/task-a-two-words.csv`\n",
    "- `data/task-b1.tsv`\n",
    "- `data/task-b2.tsv`\n",
    "\n",
    "For each file, samples **100 random rows** (or fewer if file has fewer rows) and writes **CSV** outputs to:\n",
    "`data/generated_data/test_subsets/`\n",
    "\n",
    "Also writes a manifest with sampled indices: `test_subsets_manifest.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a28a8df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T17:12:25.822604Z",
     "start_time": "2025-12-31T17:12:25.817509Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 100\n",
    "\n",
    "INPUTS = [\n",
    "    (\"task-a-title.csv\", \"tab\"),        # tab-separated values, despite .csv extension\n",
    "    (\"task-a-two-words.csv\", \"tab\"),    # tab-separated values, despite .csv extension\n",
    "    (\"task-b1.tsv\", \"tab\"),\n",
    "    (\"task-b2.tsv\", \"tab\"),\n",
    "]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "c8cf7b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T17:12:25.830284Z",
     "start_time": "2025-12-31T17:12:25.824509Z"
    }
   },
   "source": [
    "def find_project_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    here = start\n",
    "    for _ in range(12):\n",
    "        data_dir = here / \"data\"\n",
    "        if data_dir.is_dir():\n",
    "            ok = True\n",
    "            for fname, _kind in INPUTS:\n",
    "                if not (data_dir / fname).exists():\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok:\n",
    "                return here\n",
    "        if here.parent == here:\n",
    "            break\n",
    "        here = here.parent\n",
    "    return start\n",
    "\n",
    "ROOT = find_project_root()\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "OUT_DIR = DATA_DIR / \"test_subsets\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", ROOT)\n",
    "print(\"Data dir:\", DATA_DIR)\n",
    "print(\"Output dir:\", OUT_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition\n",
      "Data dir: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data\n",
      "Output dir: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data/test_subsets\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "7282976f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T17:12:25.838830Z",
     "start_time": "2025-12-31T17:12:25.831388Z"
    }
   },
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "import re\n",
    "from pandas.errors import ParserError\n",
    "\n",
    "_ID_LINE_RE = re.compile(r\"^\\s*(\\d+)\\s+(.*\\S)\\s*$\")  # id + whitespace + headline\n",
    "\n",
    "def read_title_csv_loose(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust reader for task-a-title.csv.\n",
    "\n",
    "    Preferred:\n",
    "    - If file is a proper CSV with columns id/headline -> use it.\n",
    "\n",
    "    Fallback:\n",
    "    - Treat as \"one example per line\" where each line starts with a numeric id:\n",
    "        <id><whitespace><headline...>\n",
    "      This is what you want: number becomes id, remainder becomes headline.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Try proper CSV first (if it really is CSV)\n",
    "    try:\n",
    "        df = pd.read_csv(path, keep_default_na=False, engine=\"python\")\n",
    "        cols = {c.strip().lower(): c for c in df.columns}\n",
    "\n",
    "        if \"id\" in cols and \"headline\" in cols:\n",
    "            out = df[[cols[\"id\"], cols[\"headline\"]]].copy()\n",
    "            out.columns = [\"id\", \"headline\"]\n",
    "            out[\"id\"] = out[\"id\"].astype(str)\n",
    "            out[\"headline\"] = out[\"headline\"].astype(str)\n",
    "            return out\n",
    "    except ParserError:\n",
    "        pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Fallback: raw lines with \"<id> <headline>\"\n",
    "    lines = path.read_text(encoding=\"utf-8\", errors=\"replace\").splitlines()\n",
    "    rows = []\n",
    "    for ln in lines:\n",
    "        ln = ln.strip()\n",
    "        if not ln:\n",
    "            continue\n",
    "        low = ln.lower()\n",
    "        if low in {\"headline\", \"id\\theadline\", \"id,headline\"}:\n",
    "            continue\n",
    "\n",
    "        m = _ID_LINE_RE.match(ln)\n",
    "        if m:\n",
    "            rows.append((m.group(1), m.group(2)))\n",
    "        else:\n",
    "            # If a line has no numeric prefix, keep it but use its line index as id\n",
    "            # (this should be rare; remove this block if you prefer to skip such lines)\n",
    "            rows.append((str(len(rows)), ln))\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"id\", \"headline\"])\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_table(path: Path, kind: str) -> pd.DataFrame:\n",
    "    if kind == \"tab\":\n",
    "        df = pd.read_csv(path, sep=\"\\t\", keep_default_na=False, engine=\"python\")\n",
    "\n",
    "        # Many of these files have an extra first column (index) with an empty header.\n",
    "        # Drop it if it exists.\n",
    "        first_col = df.columns[0]\n",
    "        if first_col == \"\" or str(first_col).startswith(\"Unnamed\"):\n",
    "            df = df.drop(columns=[first_col])\n",
    "\n",
    "        return df\n",
    "\n",
    "    raise ValueError(f\"Unknown kind: {kind}\")\n",
    "\n",
    "\n",
    "def sample_indices(n_rows: int, n_samples: int) -> list[int]:\n",
    "    k = min(n_rows, n_samples)\n",
    "    idx = rng.choice(n_rows, size=k, replace=False)\n",
    "    idx = np.sort(idx)\n",
    "    return [int(i) for i in idx]\n",
    "\n",
    "def ensure_id_column(df: pd.DataFrame, source_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure there is an 'id' column. If missing, create a stable id from row position.\n",
    "    \"\"\"\n",
    "    if \"id\" in df.columns:\n",
    "        df[\"id\"] = df[\"id\"].astype(str)\n",
    "        return df\n",
    "\n",
    "    # Create stable IDs (use source_name prefix to avoid collisions across files)\n",
    "    df = df.copy()\n",
    "    df.insert(0, \"id\", [f\"{source_name}_{i:06d}\" for i in range(len(df))])\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_subset_csv(input_path: Path, kind: str, out_dir: Path, n_samples: int) -> dict:\n",
    "    df = read_table(input_path, kind)\n",
    "\n",
    "    # Ensure id column exists BEFORE sampling\n",
    "    df = ensure_id_column(df, source_name=input_path.stem)\n",
    "\n",
    "    idx = sample_indices(len(df), n_samples)\n",
    "    subset = df.iloc[idx].copy()\n",
    "\n",
    "    if input_path.name == \"task-a-title.csv\":\n",
    "        subset = subset[[\"id\", \"headline\"]]\n",
    "        \n",
    "    if input_path.name == \"task-a-two-words.csv\":\n",
    "        subset = subset[[\"id\", \"word1\", \"word2\", \"headline\"]]\n",
    "\n",
    "    # Always write CSV outputs\n",
    "    out_path = out_dir / (input_path.stem + f\".test{len(idx)}.csv\")\n",
    "    subset.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "\n",
    "    return {\n",
    "        \"input\": str(input_path),\n",
    "        \"output\": str(out_path),\n",
    "        \"rows_in\": int(len(df)),\n",
    "        \"rows_out\": int(len(subset)),\n",
    "        \"indices\": idx,\n",
    "        \"seed\": int(SEED),\n",
    "    }\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "9978b65a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T17:12:25.863725Z",
     "start_time": "2025-12-31T17:12:25.839725Z"
    }
   },
   "source": [
    "results = []\n",
    "for fname, kind in INPUTS:\n",
    "    inp = DATA_DIR / fname\n",
    "    if not inp.exists():\n",
    "        raise FileNotFoundError(f\"Missing input file: {inp}\")\n",
    "    meta = make_subset_csv(inp, kind, OUT_DIR, N_SAMPLES)\n",
    "    results.append(meta)\n",
    "    print(f\"✅ {fname}: {meta['rows_in']} -> {meta['rows_out']} rows\")\n",
    "    print(\"   ->\", meta[\"output\"])\n",
    "\n",
    "manifest = OUT_DIR / \"test_subsets_manifest.json\"\n",
    "manifest.write_text(json.dumps(\n",
    "    {\n",
    "        \"seed\": SEED,\n",
    "        \"n_samples\": N_SAMPLES,\n",
    "        \"created_utc\": __import__(\"datetime\").datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"subsets\": results,\n",
    "    },\n",
    "    indent=2\n",
    "), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nSaved manifest:\", manifest)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ task-a-title.csv: 1100 -> 100 rows\n",
      "   -> /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data/test_subsets/task-a-title.test100.csv\n",
      "✅ task-a-two-words.csv: 100 -> 100 rows\n",
      "   -> /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data/test_subsets/task-a-two-words.test100.csv\n",
      "✅ task-b1.tsv: 1100 -> 100 rows\n",
      "   -> /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data/test_subsets/task-b1.test100.csv\n",
      "✅ task-b2.tsv: 500 -> 100 rows\n",
      "   -> /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data/test_subsets/task-b2.test100.csv\n",
      "\n",
      "Saved manifest: /Users/andrey/Documents/_Artemis_tum/Semester5/MWAHAHA_Competition/data/test_subsets/test_subsets_manifest.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2q/qf84z8xs67vfwjt96dblpb9c0000gn/T/ipykernel_15033/1153509624.py:16: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"created_utc\": __import__(\"datetime\").datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "id": "c6e66603",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "You should now have **4 CSV files** in `data/generated_data/test_subsets/`:\n",
    "\n",
    "- `task-a-title.test100.csv`\n",
    "- `task-a-two-words.test100.csv`\n",
    "- `task-b1.test100.csv`\n",
    "- `task-b2.test100.csv`\n",
    "\n",
    "(If any source has fewer than 100 rows, the output will be `.test<N>.csv` accordingly.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

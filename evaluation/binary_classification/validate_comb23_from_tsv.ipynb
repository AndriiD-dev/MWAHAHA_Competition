{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ae3bf6",
   "metadata": {},
   "source": [
    "# Validate `Humor-Research/humor-detection-comb-23` on a TSV file\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads a TSV file.\n",
    "2. Feeds the **`prediction`** column (text) into the model `Humor-Research/humor-detection-comb-23`.\n",
    "3. Adds per-row probabilities and predicted labels.\n",
    "4. Summarizes:\n",
    "   - **average certainty for predicted non-jokes (label 0)**\n",
    "   - **average certainty for predicted jokes (label 1)**\n",
    "   - **count of predicted non-jokes and jokes**\n",
    "\n",
    "> Note: The Humor-Research model repositories typically do not include tokenizer files, so we load the tokenizer from `roberta-base` (this is also the usage shown by the authors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, uncomment and run once:\n",
    "# %pip install -q torch transformers pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91a6797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonii/nlp_repo/MWAHAHA_Competition/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1\n",
      "transformers: 4.57.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, RobertaTokenizerFast\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "import transformers\n",
    "print(\"transformers:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d00344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "\n",
    "TSV_FILE = \"task-a-title_predictions_base 6 (all jokes generated)\"\n",
    "TSV_PATH = f\"../../experiment_results_good/{TSV_FILE}.tsv\"   # <-- set your TSV path here\n",
    "TEXT_COLUMN = \"prediction\"             # <-- the column to score with the model\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 256  # 512 is fine too; 256 is usually enough for short jokes\n",
    "\n",
    "OUT_DIR = \"results_exp_good\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "MODEL_ID = \"Humor-Research/humor-detection-comb-23\"\n",
    "TOKENIZER_ID = \"roberta-base\"  # tokenizer comes from roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b756a52",
   "metadata": {},
   "source": [
    "## Load TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf8009a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1100\n",
      "Columns: ['Unnamed: 0', 'headline', 'noun1', 'noun2', 'prediction']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>noun1</th>\n",
       "      <th>noun2</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ryanair to cut 1 million more passenger seats ...</td>\n",
       "      <td>seat</td>\n",
       "      <td>spain</td>\n",
       "      <td>Ryanair's cutting seats in Spain? Pricey irony...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Looted by Nazis, a 17th-Century Painting Resur...</td>\n",
       "      <td>painting</td>\n",
       "      <td>long</td>\n",
       "      <td>A 17th-century painting so long it needs glass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Analysis: Spotlight on childcare reforms revea...</td>\n",
       "      <td>spotlight</td>\n",
       "      <td>reform</td>\n",
       "      <td>Spotlight often shines where there's no need, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Do body wipes actually work? Experts weigh in</td>\n",
       "      <td>wipe</td>\n",
       "      <td>body</td>\n",
       "      <td>Experts weigh in: Do body wipes actually work?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Is Meghan’s Netflix series another ‘exercise i...</td>\n",
       "      <td>exercise</td>\n",
       "      <td>series</td>\n",
       "      <td>Is 'The Meghan Show' really just another exerc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline      noun1  \\\n",
       "0           0  Ryanair to cut 1 million more passenger seats ...       seat   \n",
       "1           1  Looted by Nazis, a 17th-Century Painting Resur...   painting   \n",
       "2           2  Analysis: Spotlight on childcare reforms revea...  spotlight   \n",
       "3           3      Do body wipes actually work? Experts weigh in       wipe   \n",
       "4           4  Is Meghan’s Netflix series another ‘exercise i...   exercise   \n",
       "\n",
       "    noun2                                         prediction  \n",
       "0   spain  Ryanair's cutting seats in Spain? Pricey irony...  \n",
       "1    long  A 17th-century painting so long it needs glass...  \n",
       "2  reform  Spotlight often shines where there's no need, ...  \n",
       "3    body  Experts weigh in: Do body wipes actually work?...  \n",
       "4  series  Is 'The Meghan Show' really just another exerc...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(TSV_PATH):\n",
    "    raise FileNotFoundError(f\"TSV file not found: {TSV_PATH}\")\n",
    "\n",
    "df = pd.read_csv(TSV_PATH, sep=\"\\t\")\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "if TEXT_COLUMN not in df.columns:\n",
    "    raise KeyError(f\"Column '{TEXT_COLUMN}' not found. Available columns: {list(df.columns)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e719a7c9",
   "metadata": {},
   "source": [
    "## Load model + tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6ddfc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: Humor-Research/humor-detection-comb-23\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(TOKENIZER_ID)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded:\", MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb81b4",
   "metadata": {},
   "source": [
    "## Score the TSV (probabilities and predictions)\n",
    "\n",
    "We compute:\n",
    "\n",
    "- `p_not_joke` = probability of label 0  \n",
    "- `p_joke` = probability of label 1  \n",
    "- `model_pred` = argmax label (0 or 1)  \n",
    "- `certainty` = probability of the predicted label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7afc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 35/35 [00:07<00:00,  4.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>noun1</th>\n",
       "      <th>noun2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>p_not_joke</th>\n",
       "      <th>p_joke</th>\n",
       "      <th>model_pred</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ryanair to cut 1 million more passenger seats ...</td>\n",
       "      <td>seat</td>\n",
       "      <td>spain</td>\n",
       "      <td>Ryanair's cutting seats in Spain? Pricey irony...</td>\n",
       "      <td>0.097718</td>\n",
       "      <td>0.902282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Looted by Nazis, a 17th-Century Painting Resur...</td>\n",
       "      <td>painting</td>\n",
       "      <td>long</td>\n",
       "      <td>A 17th-century painting so long it needs glass...</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>0.986874</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Analysis: Spotlight on childcare reforms revea...</td>\n",
       "      <td>spotlight</td>\n",
       "      <td>reform</td>\n",
       "      <td>Spotlight often shines where there's no need, ...</td>\n",
       "      <td>0.990283</td>\n",
       "      <td>0.009717</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Do body wipes actually work? Experts weigh in</td>\n",
       "      <td>wipe</td>\n",
       "      <td>body</td>\n",
       "      <td>Experts weigh in: Do body wipes actually work?...</td>\n",
       "      <td>0.210402</td>\n",
       "      <td>0.789598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Is Meghan’s Netflix series another ‘exercise i...</td>\n",
       "      <td>exercise</td>\n",
       "      <td>series</td>\n",
       "      <td>Is 'The Meghan Show' really just another exerc...</td>\n",
       "      <td>0.762909</td>\n",
       "      <td>0.237091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline      noun1  \\\n",
       "0           0  Ryanair to cut 1 million more passenger seats ...       seat   \n",
       "1           1  Looted by Nazis, a 17th-Century Painting Resur...   painting   \n",
       "2           2  Analysis: Spotlight on childcare reforms revea...  spotlight   \n",
       "3           3      Do body wipes actually work? Experts weigh in       wipe   \n",
       "4           4  Is Meghan’s Netflix series another ‘exercise i...   exercise   \n",
       "\n",
       "    noun2                                         prediction  p_not_joke  \\\n",
       "0   spain  Ryanair's cutting seats in Spain? Pricey irony...    0.097718   \n",
       "1    long  A 17th-century painting so long it needs glass...    0.013126   \n",
       "2  reform  Spotlight often shines where there's no need, ...    0.990283   \n",
       "3    body  Experts weigh in: Do body wipes actually work?...    0.210402   \n",
       "4  series  Is 'The Meghan Show' really just another exerc...    0.762909   \n",
       "\n",
       "     p_joke  model_pred  certainty  \n",
       "0  0.902282           1   0.902282  \n",
       "1  0.986874           1   0.986874  \n",
       "2  0.009717           0   0.990283  \n",
       "3  0.789598           1   0.789598  \n",
       "4  0.237091           0   0.762909  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def score_texts(texts):\n",
    "    all_p0 = []\n",
    "    all_p1 = []\n",
    "    for start in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"Scoring\"):\n",
    "        batch_texts = texts[start:start+BATCH_SIZE]\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        logits = model(**enc).logits  # [batch, 2]\n",
    "        probs = torch.softmax(logits, dim=-1).detach().cpu()  # [batch, 2]\n",
    "        all_p0.extend(probs[:, 0].tolist())\n",
    "        all_p1.extend(probs[:, 1].tolist())\n",
    "    return all_p0, all_p1\n",
    "\n",
    "texts = df[TEXT_COLUMN].astype(str).tolist()\n",
    "p0, p1 = score_texts(texts)\n",
    "\n",
    "df[\"p_not_joke\"] = p0\n",
    "df[\"p_joke\"] = p1\n",
    "df[\"model_pred\"] = (df[\"p_joke\"] > df[\"p_not_joke\"]).astype(int)\n",
    "df[\"certainty\"] = df.apply(lambda r: r[\"p_joke\"] if r[\"model_pred\"] == 1 else r[\"p_not_joke\"], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e33a7",
   "metadata": {},
   "source": [
    "## Summary: average certainties and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d9ec51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>not_joke</td>\n",
       "      <td>418</td>\n",
       "      <td>0.409027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joke</td>\n",
       "      <td>682</td>\n",
       "      <td>0.590973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_label label_name  count  avg_certainty\n",
       "0                0   not_joke    418       0.409027\n",
       "1                1       joke    682       0.590973"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts\n",
    "count_not_joke = int((df[\"model_pred\"] == 0).sum())\n",
    "count_joke = int((df[\"model_pred\"] == 1).sum())\n",
    "\n",
    "# Average certainty for each predicted class:\n",
    "avg_not_joke_certainty = float(df[\"p_not_joke\"].mean()) if count_not_joke else float(\"nan\")\n",
    "avg_joke_certainty = float(df[\"p_joke\"].mean()) if count_joke else float(\"nan\")\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"predicted_label\": 0, \"label_name\": \"not_joke\", \"count\": count_not_joke, \"avg_certainty\": avg_not_joke_certainty},\n",
    "    {\"predicted_label\": 1, \"label_name\": \"joke\", \"count\": count_joke, \"avg_certainty\": avg_joke_certainty},\n",
    "])\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "075e427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted not_joke count: 418 | average certainty: 0.4090266063841144\n",
      "Predicted joke count    : 682 | average certainty: 0.5909733923721466\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted not_joke count:\", count_not_joke, \"| average certainty:\", avg_not_joke_certainty)\n",
    "print(\"Predicted joke count    :\", count_joke,     \"| average certainty:\", avg_joke_certainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f29f74",
   "metadata": {},
   "source": [
    "## Save outputs\n",
    "\n",
    "- `output/comb23_scored_with_summary.tsv` – your original TSV plus probabilities and predictions + summary table (counts and average certainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c60c57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved single TSV (scored + summary): results_exp_good/task-a-title_predictions_base 6 (all jokes generated)_scored_with_summary.tsv\n"
     ]
    }
   ],
   "source": [
    "# Save outputs (single file)\n",
    "\n",
    "# We will write everything to ONE TSV file:\n",
    "# 1) the scored rows (original TSV + probabilities + predictions)\n",
    "# 2) a blank line\n",
    "# 3) a small summary block with counts + average certainties\n",
    "\n",
    "single_path = os.path.join(OUT_DIR, f\"{TSV_FILE}_scored_with_summary.tsv\")\n",
    "\n",
    "# 1) write scored rows\n",
    "df.to_csv(single_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# 2) append summary block\n",
    "with open(single_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"# summary\\n\")\n",
    "    f.write(f\"# predicted_not_joke_count\\t{count_not_joke}\\n\")\n",
    "    f.write(f\"# predicted_joke_count\\t{count_joke}\\n\")\n",
    "    f.write(f\"# avg_not_joke_certainty\\t{avg_not_joke_certainty}\\n\")\n",
    "    f.write(f\"# avg_joke_certainty\\t{avg_joke_certainty}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    # also append the summary table as TSV\n",
    "    summary.to_csv(f, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Saved single TSV (scored + summary):\", single_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
